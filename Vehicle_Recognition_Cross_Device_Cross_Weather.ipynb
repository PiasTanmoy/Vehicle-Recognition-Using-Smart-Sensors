{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Vehicle Recognition - Cross Device - Cross Weather.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IKOCXD02xgN0UbmhdOS2-V-W7zpAsVQD",
      "authorship_tag": "ABX9TyOcpqzatc9XqU0O5xbYND7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiasTanmoy/Vehicle-Recognition-Using-Smart-Sensors/blob/main/Vehicle_Recognition_Cross_Device_Cross_Weather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import "
      ],
      "metadata": {
        "id": "OvyvXS5gQA4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "plt.rcParams.update({'font.size': 12})"
      ],
      "metadata": {
        "id": "6U_s3jZeBsKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read dataset"
      ],
      "metadata": {
        "id": "TY-aPoi5QDaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h30CNdcwpFO"
      },
      "outputs": [],
      "source": [
        "car = pd.read_csv('/content/drive/Shareddrives/Vehicle Recognition - Sensor/Data/car-pias.csv')\n",
        "bus = pd.read_csv('/content/drive/Shareddrives/Vehicle Recognition - Sensor/Data/bus-pias.csv')\n",
        "bike = pd.read_csv('/content/drive/Shareddrives/Vehicle Recognition - Sensor/Data/bike-david.csv')\n",
        "rail = pd.read_csv('/content/drive/Shareddrives/Vehicle Recognition - Sensor/Data/NEW RAIL/rail1b.csv')\n",
        "\n",
        "car_rain = pd.read_csv('/content/drive/Shareddrives/Vehicle Recognition - Sensor/Data/car-dave-rain.csv')\n",
        "car_rain_newark_light = pd.read_csv('/content/drive/Shareddrives/Vehicle Recognition - Sensor/Data/car-city-newark-light-rain.csv')\n",
        "car_clear = pd.read_csv('/content/drive/Shareddrives/Vehicle Recognition - Sensor/Data/car-david-clear.csv')\n",
        "\n",
        "rail_ag = rail[['ax', 'ay', 'az', 'wx', 'wy', 'wz']]\n",
        "bus_ag = bus[['ax', 'ay', 'az', 'wx', 'wy', 'wz']]\n",
        "bike_ag = bike[['ax', 'ay', 'az', 'wx', 'wy', 'wz']]\n",
        "car_ag = car[['ax', 'ay', 'az', 'wx', 'wy', 'wz']]\n",
        "\n",
        "car_rain_ag = car_rain[['ax', 'ay', 'az', 'wx', 'wy', 'wz']]\n",
        "car_rain_newark_light_ag = car_rain_newark_light[['ax', 'ay', 'az', 'wx', 'wy', 'wz']]\n",
        "car_clear_ag = car_clear[['ax', 'ay', 'az', 'wx', 'wy', 'wz']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "GsUK7INvHUxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preprocesing"
      ],
      "metadata": {
        "id": "JrdTOhec9I0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter: FL = File length**"
      ],
      "metadata": {
        "id": "NmZVmCYr-vWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FL = 2800 # minimum of all files, the more the better. FL=20,000 is better than FL=2,000\n",
        "\n",
        "car_ag_fl = car_ag[:FL] \n",
        "rail_ag_fl = rail_ag[:FL]\n",
        "bus_ag_fl = bus_ag[:FL]\n",
        "bike_ag_fl = bike_ag[:FL]\n",
        "\n",
        "# generate class label\n",
        "c0 = np.full((FL), 0).reshape(FL, 1)\n",
        "c1 = np.full((FL), 1).reshape(FL, 1)\n",
        "c2 = np.full((FL), 2).reshape(FL, 1)\n",
        "c3 = np.full((FL), 3).reshape(FL, 1)\n",
        "\n",
        "print(car_ag_fl.shape, rail_ag_fl.shape, bus_ag_fl.shape, bike_ag_fl.shape, c0.shape, c1.shape, c2.shape, c3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No8j-PvF9IZa",
        "outputId": "1f9b2afc-e8ee-42b2-c71e-d17f2d521c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2800, 6) (2800, 6) (2800, 6) (2800, 6) (2800, 1) (2800, 1) (2800, 1) (2800, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Weather**"
      ],
      "metadata": {
        "id": "3pWPX6_5agMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FL = 2800 # minimum of all files, the more the better. FL=20,000 is better than FL=2,000\n",
        "\n",
        "car_clear_fl = car_clear_ag[:FL] \n",
        "car_rain_ag_fl = car_rain_ag[:FL]\n",
        "car_rain_newark_light_ag_fl = car_rain_newark_light_ag[:FL]\n",
        "car_ag_fl = car_ag[:FL] \n",
        "\n",
        "rail_ag_fl = rail_ag[:FL]\n",
        "bus_ag_fl = bus_ag[:FL]\n",
        "bike_ag_fl = bike_ag[:FL]\n",
        "\n",
        "# generate class label\n",
        "c0 = np.full((FL*4), 0).reshape(FL*4, 1)\n",
        "c1 = np.full((FL), 1).reshape(FL, 1)\n",
        "c2 = np.full((FL), 2).reshape(FL, 1)\n",
        "c3 = np.full((FL), 3).reshape(FL, 1)\n",
        "\n",
        "print(car_clear_fl.shape, car_rain_ag_fl.shape, car_rain_newark_light_ag_fl.shape, c0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4BHOVoAa2GG",
        "outputId": "1641f931-e10a-4799-b250-ab6832262598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2800, 6) (2800, 6) (2800, 6) (11200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Way 1: Sliding window segmentation"
      ],
      "metadata": {
        "id": "AHigX4VXxcWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_dataset(data_class, seg = 200):\n",
        "  car_np = data_class.to_numpy()\n",
        "  car_seg = []\n",
        "  for i in range(car_np.shape[0] - seg):\n",
        "    car_seg.append(car_np[i:i+seg])\n",
        "  car_seg = np.array(car_seg) \n",
        "  return car_seg\n",
        "\n",
        "\n",
        "car_seg = segment_dataset(car_ag_fl)\n",
        "rail_seg = segment_dataset(rail_ag_fl)\n",
        "bus_seg = segment_dataset(bus_ag_fl)\n",
        "bike_seg = segment_dataset(bike_ag_fl)\n",
        "\n",
        "length = car_seg.shape[0]\n",
        "# generate class label\n",
        "c0 = np.full((length), 0)\n",
        "c1 = np.full((length), 1)\n",
        "c2 = np.full((length), 2)\n",
        "c3 = np.full((length), 3)\n",
        "\n",
        "print(car_seg.shape, c0.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "\n",
        "X = np.concatenate((car_seg, rail_seg, bus_seg, bike_seg), axis=0)\n",
        "\n",
        "Y = np.concatenate((c0, c1, c2, c3), axis = None)\n",
        "Y = to_categorical(Y)\n",
        "\n",
        "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "trainX.shape, testX.shape, trainY.shape, testY.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORoIotOnx-5e",
        "outputId": "c08b9384-21b0-4dfd-becc-799ffaebd563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2600, 200, 6) (2600,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8320, 200, 6), (2080, 200, 6), (8320, 4), (2080, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Weather"
      ],
      "metadata": {
        "id": "l8lGHdH-qc9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_dataset(data_class, seg = 200):\n",
        "  car_np = data_class.to_numpy()\n",
        "  car_seg = []\n",
        "  for i in range(car_np.shape[0] - seg):\n",
        "    car_seg.append(car_np[i:i+seg])\n",
        "  car_seg = np.array(car_seg) \n",
        "  return car_seg\n",
        "\n",
        "car_rain_seg = segment_dataset(car_rain_ag_fl)\n",
        "#car_rain_newark_light_seg = segment_dataset(car_rain_newark_light_ag_fl)\n",
        "\n",
        "car_clear_seg = segment_dataset(car_clear_fl)\n",
        "#car_seg = segment_dataset(car_ag_fl)\n",
        "\n",
        "rail_seg = segment_dataset(rail_ag_fl)\n",
        "bus_seg = segment_dataset(bus_ag_fl)\n",
        "bike_seg = segment_dataset(bike_ag_fl)\n",
        "\n",
        "length = car_seg.shape[0]\n",
        "\n",
        "# generate class label\n",
        "c0 = np.full((length), 0)\n",
        "c1 = np.full((length), 1)\n",
        "c2 = np.full((length), 2)\n",
        "c3 = np.full((length), 3)\n",
        "\n",
        "print(car_seg.shape, c1.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "\n",
        "trainX = np.concatenate((car_clear_seg, rail_seg, bus_seg, bike_seg), axis=0)\n",
        "testX = np.concatenate((car_rain_seg, rail_seg, bus_seg, bike_seg), axis=0)\n",
        "\n",
        "Y = np.concatenate((c0, c1, c2, c3), axis = None)\n",
        "trainY = to_categorical(Y)\n",
        "testY = to_categorical(Y)\n",
        "\n",
        "trainX.shape, testX.shape, trainY.shape, testY.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZRTZ89pqYSm",
        "outputId": "abe08768-591d-4157-fccc-15087dae0f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2600, 200, 6) (2600,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10400, 200, 6), (10400, 200, 6), (10400, 4), (10400, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Weather"
      ],
      "metadata": {
        "id": "2VpZonddj0fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_dataset(data_class, seg = 200):\n",
        "  car_np = data_class.to_numpy()\n",
        "  car_seg = []\n",
        "  for i in range(car_np.shape[0] - seg):\n",
        "    car_seg.append(car_np[i:i+seg])\n",
        "  car_seg = np.array(car_seg) \n",
        "  return car_seg\n",
        "\n",
        "\n",
        "car_clear_seg = segment_dataset(car_clear_fl)\n",
        "car_rain_seg = segment_dataset(car_rain_ag_fl)\n",
        "car_rain_newark_light_seg = segment_dataset(car_rain_newark_light_ag_fl)\n",
        "\n",
        "car_seg = segment_dataset(car_ag_fl)\n",
        "rail_seg = segment_dataset(rail_ag_fl)\n",
        "bus_seg = segment_dataset(bus_ag_fl)\n",
        "bike_seg = segment_dataset(bike_ag_fl)\n",
        "\n",
        "length = car_seg.shape[0]\n",
        "# generate class label\n",
        "c0 = np.full((length*4), 0)\n",
        "c1 = np.full((length), 1)\n",
        "c2 = np.full((length), 2)\n",
        "c3 = np.full((length), 3)\n",
        "\n",
        "print(car_seg.shape, c1.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "\n",
        "X = np.concatenate((car_clear_seg, car_rain_seg, car_rain_newark_light_seg, car_seg, rail_seg, bus_seg, bike_seg), axis=0)\n",
        "\n",
        "Y = np.concatenate((c0, c1, c2, c3), axis = None)\n",
        "Y = to_categorical(Y)\n",
        "\n",
        "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "trainX.shape, testX.shape, trainY.shape, testY.shape"
      ],
      "metadata": {
        "id": "As3vempKj6Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run**"
      ],
      "metadata": {
        "id": "yOeUjPuHj8IY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter:**"
      ],
      "metadata": {
        "id": "cr4LIAP5ABoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2 # depends on the number of classes\n",
        "#input_shape = (trainX_np.shape[1], trainX_np.shape[2]) # depends on the dimension of the dataset\n",
        "input_shape = (trainX.shape[1], trainX.shape[2]) # depends on the dimension of the dataset\n",
        "\n",
        "print(num_classes, input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg8IA9vc_2Gq",
        "outputId": "f3f1cebe-575f-4f83-d58c-f83cf6edbf02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 (200, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model"
      ],
      "metadata": {
        "id": "xG7ozjWUfSMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(input_shape):\n",
        "  #input_layer = keras.layers.Input(input_shape)\n",
        "  \n",
        "  input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "  conv1 = keras.layers.Conv1D(filters=64, kernel_size=9, padding=\"same\")(input_layer)\n",
        "  conv1 = keras.layers.BatchNormalization()(conv1)\n",
        "  conv1 = keras.layers.ReLU()(conv1)\n",
        "  conv1 = MaxPooling1D(pool_size=(2)) (conv1)\n",
        "\n",
        "  conv2 = keras.layers.Conv1D(filters=64, kernel_size=9, padding=\"same\")(conv1)\n",
        "  conv2 = keras.layers.BatchNormalization()(conv2)\n",
        "  conv2 = keras.layers.ReLU()(conv2)\n",
        "  conv2 = MaxPooling1D(pool_size=(2)) (conv2)\n",
        "\n",
        "  conv3 = keras.layers.Conv1D(filters=64, kernel_size=9, padding=\"same\")(conv2)\n",
        "  conv3 = keras.layers.BatchNormalization()(conv3)\n",
        "  conv3 = keras.layers.ReLU()(conv3)\n",
        "  conv3 = MaxPooling1D(pool_size=(2)) (conv3)\n",
        "\n",
        "  connect1 = concatenate([conv1, conv2, conv3], axis=1)\n",
        "\n",
        "\n",
        "  gap = keras.layers.GlobalAveragePooling1D()(connect1)\n",
        "\n",
        "  flat = Flatten() (gap)\n",
        "\n",
        "  dense1 = Dense(1024, activation='relu') (flat)\n",
        "  drop1 = Dropout(0.5) (dense1)\n",
        "\n",
        "  dense2 = Dense(256, activation='relu') (drop1)\n",
        "  drop2 = Dropout(0.5) (dense2)\n",
        "\n",
        "  dense3 = Dense(64, activation='relu') (drop2)\n",
        "  drop3 = Dropout(0.5) (dense3)\n",
        "\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(dense3)\n",
        "\n",
        "  return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "#input_shape = (100, 6)\n",
        "#num_classes = 4\n",
        "model = make_model(input_shape=input_shape)\n",
        "print(input_shape)\n",
        "#keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkWdJ2gLfRv-",
        "outputId": "60f941d6-c032-4898-e97f-8bf0d1bebd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "vekCB6kN9A4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "kfhinMjj9Is9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter**"
      ],
      "metadata": {
        "id": "5JX0qRO_C7Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10 # range: 10-1000 \n",
        "batch_size = 64 # 1, 2, 4, 8, ...., up to length of dataset"
      ],
      "metadata": {
        "id": "QZ1ibJENDak5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model_win_200.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
        "]\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=keras.losses.categorical_crossentropy,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    trainX,\n",
        "    trainY,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_split = 0.2,\n",
        "    verbose=1,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KQARg4aCD6z",
        "outputId": "4b5d153d-b853-4e1f-9c7e-261baa50d2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "182/182 [==============================] - 24s 125ms/step - loss: 0.1988 - accuracy: 0.9313 - val_loss: 0.2047 - val_accuracy: 0.9320 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "182/182 [==============================] - 26s 141ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0019 - val_accuracy: 0.9997 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "182/182 [==============================] - 21s 113ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.0050 - val_accuracy: 0.9973 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "182/182 [==============================] - 21s 114ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 2.4390e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "182/182 [==============================] - 21s 113ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 3.1962e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "182/182 [==============================] - 21s 113ms/step - loss: 0.0219 - accuracy: 0.9943 - val_loss: 6.9054e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "182/182 [==============================] - 21s 113ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 4.9195e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "182/182 [==============================] - 21s 113ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 8.2916e-06 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "182/182 [==============================] - 20s 112ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "182/182 [==============================] - 20s 112ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 1.3891e-04 - val_accuracy: 1.0000 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = keras.models.load_model(\"best_model.h5\")\n",
        "\n",
        "#test_loss, test_acc = model.evaluate(testX, testY)\n",
        "test_loss, test_acc = model.evaluate(testX, testY)\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdBFG1CtDxEZ",
        "outputId": "51890971-f691-4634-aaa1-8755277f8343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114/114 [==============================] - 2s 16ms/step - loss: 1.1963e-04 - accuracy: 1.0000\n",
            "Test accuracy 1.0\n",
            "Test loss 0.00011963181896135211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Model**"
      ],
      "metadata": {
        "id": "L8mxZT3kxlGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/Shareddrives/Vehicle Recognition - Sensor/Code/model weights/best_model_accuracy_100.h5')"
      ],
      "metadata": {
        "id": "kTgCp-ItxkhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Saved Model**"
      ],
      "metadata": {
        "id": "XJfeuzy_st-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model_loaded = load_model('/content/drive/Shareddrives/Vehicle Recognition - Sensor/Code/model weights/best_model_accuracy_100.h5')\n",
        "score = model_loaded.evaluate(testX, testY, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5O2wxckqsHP",
        "outputId": "8f36f1d1-8ca3-49e1-b5f7-00a07cf64bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "407/407 [==============================] - 6s 15ms/step - loss: 1.0501e-04 - accuracy: 1.0000\n",
            "Test loss: 0.00010500555072212592\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Weather"
      ],
      "metadata": {
        "id": "f4krSvlZx5mP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_model(input_shape=input_shape)\n",
        "epochs = 10 # range: 10-1000 \n",
        "batch_size = 64 # 1, 2, 4, 8, ...., up to length of dataset\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model_cross_weather.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
        "]\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=keras.losses.categorical_crossentropy,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    trainX,\n",
        "    trainY,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_split = 0.2,\n",
        "    verbose=1,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MKd_MH4x8PW",
        "outputId": "f21782ab-869e-4b00-f156-7939a428fa87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "130/130 [==============================] - 15s 109ms/step - loss: 0.1996 - accuracy: 0.9266 - val_loss: 5.7587 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "130/130 [==============================] - 14s 109ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 5.1954 - val_accuracy: 0.1149 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "130/130 [==============================] - 14s 109ms/step - loss: 2.6109e-04 - accuracy: 1.0000 - val_loss: 1.8507 - val_accuracy: 0.6130 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "130/130 [==============================] - 15s 113ms/step - loss: 1.5369e-04 - accuracy: 1.0000 - val_loss: 1.2871 - val_accuracy: 0.7553 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "130/130 [==============================] - 15s 118ms/step - loss: 1.3505e-04 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8183 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "130/130 [==============================] - 14s 107ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.4184 - val_accuracy: 0.8620 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "130/130 [==============================] - 15s 112ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4520 - val_accuracy: 0.8611 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "130/130 [==============================] - 14s 109ms/step - loss: 1.4919e-04 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.8663 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "130/130 [==============================] - 14s 110ms/step - loss: 2.0464e-04 - accuracy: 1.0000 - val_loss: 0.9305 - val_accuracy: 0.8389 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "130/130 [==============================] - 14s 109ms/step - loss: 1.1324e-04 - accuracy: 1.0000 - val_loss: 0.5880 - val_accuracy: 0.8423 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_loss, test_acc = model.evaluate(testX, testY)\n",
        "test_loss, test_acc = model.evaluate(testX, testY)\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI3OYsjx1iW9",
        "outputId": "00ddc36a-79e4-466e-c863-1ed7ee5aeaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "325/325 [==============================] - 5s 14ms/step - loss: 0.1299 - accuracy: 0.9633\n",
            "Test accuracy 0.9632692337036133\n",
            "Test loss 0.12989501655101776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/Shareddrives/Vehicle Recognition - Sensor/Code/model weights/cross_weather_accuracy_96.h5')"
      ],
      "metadata": {
        "id": "r2bk_MEa_fvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Device"
      ],
      "metadata": {
        "id": "Omfdzd7EAAD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_dataset(data_class, seg = 200):\n",
        "  car_np = data_class.to_numpy()\n",
        "  car_seg = []\n",
        "  for i in range(car_np.shape[0] - seg):\n",
        "    car_seg.append(car_np[i:i+seg])\n",
        "  car_seg = np.array(car_seg) \n",
        "  return car_seg\n",
        "\n",
        "car_seg = segment_dataset(car_ag_fl)\n",
        "\n",
        "car_clear_seg = segment_dataset(car_clear_fl)\n",
        "\n",
        "rail_seg = segment_dataset(rail_ag_fl)\n",
        "bus_seg = segment_dataset(bus_ag_fl)\n",
        "bike_seg = segment_dataset(bike_ag_fl)\n",
        "\n",
        "length = car_seg.shape[0]\n",
        "\n",
        "# generate class label\n",
        "c0 = np.full((length), 0)\n",
        "c1 = np.full((length), 1)\n",
        "c2 = np.full((length), 1)\n",
        "c3 = np.full((length), 1)\n",
        "\n",
        "print(car_seg.shape, c1.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "\n",
        "trainX = np.concatenate((car_clear_seg[:1000], rail_seg, bus_seg, bike_seg), axis=0)\n",
        "testX = np.concatenate((car_seg[:1000], rail_seg, bus_seg, bike_seg), axis=0)\n",
        "\n",
        "Y = np.concatenate((c0[:1000], c1, c2, c3), axis = None)\n",
        "trainY = to_categorical(Y)\n",
        "Y = np.concatenate((c0[:1000], c1, c2, c3), axis = None)\n",
        "testY = to_categorical(Y)\n",
        "\n",
        "trainX.shape, testX.shape, trainY.shape, testY.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3weJeo8QACNe",
        "outputId": "3067fb20-8041-43a4-8e84-198879892552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2600, 200, 6) (2600,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8800, 200, 6), (8800, 200, 6), (8800, 2), (8800, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_model(input_shape=input_shape)\n",
        "epochs = 3 # range: 10-1000 \n",
        "batch_size = 64 # 1, 2, 4, 8, ...., up to length of dataset\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model_cross_weather.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
        "]\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=keras.losses.categorical_crossentropy,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    trainX,\n",
        "    trainY,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_split = 0.2,\n",
        "    verbose=1,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D3RQWTuAQfW",
        "outputId": "0a4f9534-8509-48b2-e685-a95251f33950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "110/110 [==============================] - 13s 106ms/step - loss: 0.0945 - accuracy: 0.9509 - val_loss: 3.2556e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 2/3\n",
            "110/110 [==============================] - 14s 131ms/step - loss: 1.0548e-04 - accuracy: 1.0000 - val_loss: 1.3430e-06 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/3\n",
            "110/110 [==============================] - 11s 104ms/step - loss: 1.9874e-05 - accuracy: 1.0000 - val_loss: 9.0875e-07 - val_accuracy: 1.0000 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_loss, test_acc = model.evaluate(testX, testY)\n",
        "test_loss, test_acc = model.evaluate(testX, testY)\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMOt2FNbBEFG",
        "outputId": "caaf2b02-0249-4b2d-a480-838fc48d6d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275/275 [==============================] - 4s 14ms/step - loss: 2.9962 - accuracy: 0.9320\n",
            "Test accuracy 0.9320454597473145\n",
            "Test loss 2.9962399005889893\n"
          ]
        }
      ]
    }
  ]
}